{"cells":[{"cell_type":"markdown","metadata":{"id":"T9Ac2ZxRQSQX"},"source":["## 1. Import libraries"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YDp__OTcIN1-","executionInfo":{"status":"ok","timestamp":1702587661383,"user_tz":-420,"elapsed":23309,"user":{"displayName":"Minh Nguy·ªÖn ƒê·∫∑ng Nh·∫≠t","userId":"06013224096912534741"}},"outputId":"650306e3-7837-44ca-ed72-9272da8bf3d4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20289,"status":"ok","timestamp":1702587612488,"user":{"displayName":"Minh Nguy·ªÖn ƒê·∫∑ng Nh·∫≠t","userId":"06013224096912534741"},"user_tz":-420},"id":"nDIS0rfNQwjo","outputId":"5fd6842d-94ee-4f9f-f0b3-57957c7b340d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.0.227 üöÄ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 26.2/78.2 GB disk)\n"]}],"source":["%pip install ultralytics\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","source":["!pip install timm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZavSxZkGIku8","executionInfo":{"status":"ok","timestamp":1702587703557,"user_tz":-420,"elapsed":6474,"user":{"displayName":"Minh Nguy·ªÖn ƒê·∫∑ng Nh·∫≠t","userId":"06013224096912534741"}},"outputId":"e2890c04-b095-4dbf-bbff-984c6972072b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting timm\n","  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu121)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.4)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n","Installing collected packages: timm\n","Successfully installed timm-0.9.12\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1702587710449,"user":{"displayName":"Minh Nguy·ªÖn ƒê·∫∑ng Nh·∫≠t","userId":"06013224096912534741"},"user_tz":-420},"id":"XOyNwDmvQSQZ"},"outputs":[],"source":["import os\n","import numpy as np\n","import timm\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","from torchvision import models\n","from torchvision import transforms\n","from PIL import Image"]},{"cell_type":"markdown","metadata":{"id":"wllPSK_OQSQa"},"source":["## 2. Load model"]},{"cell_type":"markdown","metadata":{"id":"6okhGT0CQSQa"},"source":["### 2.1 Load YOLO"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2440,"status":"ok","timestamp":1702587745916,"user":{"displayName":"Minh Nguy·ªÖn ƒê·∫∑ng Nh·∫≠t","userId":"06013224096912534741"},"user_tz":-420},"id":"3VUT4dMNQSQa"},"outputs":[],"source":["from ultralytics import YOLO\n","\n","text_det_model_path = '/content/drive/MyDrive/SceneTextRecognition/Scene Text Recognition/yolov8/detect/train4/weights/best.pt'\n","yolo = YOLO(text_det_model_path)"]},{"cell_type":"markdown","metadata":{"id":"53_q4B9OQSQa"},"source":["### 2.2 Load CRNN"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":381,"status":"ok","timestamp":1702587765077,"user":{"displayName":"Minh Nguy·ªÖn ƒê·∫∑ng Nh·∫≠t","userId":"06013224096912534741"},"user_tz":-420},"id":"kz9gVQg0QSQb"},"outputs":[],"source":["class CRNN(nn.Module):\n","    def __init__(self, vocab_size, hidden_size, n_layers, dropout=0.2, unfreeze_layers=3):\n","        super(CRNN, self).__init__()\n","\n","        backbone = timm.create_model(\n","            'resnet101',\n","            in_chans=1,\n","            pretrained=True\n","        )\n","        modules = list(backbone.children())[:-2]\n","        modules.append(nn.AdaptiveAvgPool2d((1, None)))\n","        self.backbone = nn.Sequential(*modules)\n","\n","        # Unfreeze the last few layers\n","        for parameter in self.backbone[-unfreeze_layers:].parameters():\n","            parameter.requires_grad = True\n","\n","        self.mapSeq = nn.Sequential(\n","            nn.Linear(2048, 512),\n","            nn.ReLU(),\n","            nn.Dropout(dropout)\n","        )\n","\n","        self.lstm = nn.LSTM(\n","            512, hidden_size,\n","            n_layers, bidirectional=True, batch_first=True,\n","            dropout=dropout if n_layers > 1 else 0\n","        )\n","        self.layer_norm = nn.LayerNorm(hidden_size * 2)\n","\n","        self.out = nn.Sequential(\n","            nn.Linear(hidden_size * 2, vocab_size),\n","            nn.LogSoftmax(dim=2)\n","        )\n","\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = x.permute(0, 3, 1, 2)\n","        x = x.view(x.size(0), x.size(1), -1)  # Flatten the feature map\n","        x = self.mapSeq(x)\n","        x, _ = self.lstm(x)\n","        x = self.layer_norm(x)\n","        x = self.out(x)\n","        x = x.permute(1, 0, 2) # Based on CTC\n","\n","        return x"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"wzBO2WEfH3LQ","executionInfo":{"status":"ok","timestamp":1702587772388,"user_tz":-420,"elapsed":648,"user":{"displayName":"Minh Nguy·ªÖn ƒê·∫∑ng Nh·∫≠t","userId":"06013224096912534741"}}},"outputs":[],"source":["chars = '0123456789abcdefghijklmnopqrstuvwxyz-'\n","vocab_size = len(chars)\n","char_to_idx = {char: idx + 1 for idx, char in enumerate(sorted(chars))}\n","idx_to_char = {idx: char for char, idx in char_to_idx.items()}"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6618,"status":"ok","timestamp":1702587814924,"user":{"displayName":"Minh Nguy·ªÖn ƒê·∫∑ng Nh·∫≠t","userId":"06013224096912534741"},"user_tz":-420},"id":"bYBIwVFKQSQb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"81bb100e-8d4c-4241-c0b8-afaa4c0adc34"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":9}],"source":["hidden_size = 256\n","n_layers = 3\n","dropout_prob = 0.2\n","unfreeze_layers=3\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model_path = '/content/drive/MyDrive/SceneTextRecognition/Scene Text Recognition/ocr_crnn_base_best.pt'\n","\n","crnn_model = CRNN(\n","    vocab_size=vocab_size,\n","    hidden_size=hidden_size,\n","    n_layers=n_layers,\n","    dropout=dropout_prob,\n","    unfreeze_layers=unfreeze_layers\n",").to(device)\n","crnn_model.load_state_dict(torch.load(model_path))"]},{"cell_type":"markdown","metadata":{"id":"anBMAZ24QSQc"},"source":["## 3. Inference"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"SUyTbxUSH3LR","executionInfo":{"status":"ok","timestamp":1702587952962,"user_tz":-420,"elapsed":564,"user":{"displayName":"Minh Nguy·ªÖn ƒê·∫∑ng Nh·∫≠t","userId":"06013224096912534741"}}},"outputs":[],"source":["def decode(encoded_sequences, idx_to_char, blank_char='-'):\n","    decoded_sequences = []\n","\n","    for seq in encoded_sequences:\n","        decoded_label = []\n","        for idx, token in enumerate(seq):\n","            if token != 0:\n","                char = idx_to_char[token.item()]\n","                if char != blank_char:\n","                    decoded_label.append(char)\n","\n","        decoded_sequences.append(''.join(decoded_label))\n","\n","    return decoded_sequences"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"yP0CQW4vH3LR","executionInfo":{"status":"ok","timestamp":1702587964541,"user_tz":-420,"elapsed":561,"user":{"displayName":"Minh Nguy·ªÖn ƒê·∫∑ng Nh·∫≠t","userId":"06013224096912534741"}}},"outputs":[],"source":["def text_detection(img_path, text_det_model):\n","    text_det_results = text_det_model(img_path, verbose=False)[0]\n","\n","    bboxes = text_det_results.boxes.xyxy.tolist()\n","    classes = text_det_results.boxes.cls.tolist()\n","    names = text_det_results.names\n","    confs = text_det_results.boxes.conf.tolist()\n","\n","    return bboxes, classes, names, confs"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"WC_pDu1tH3LR","executionInfo":{"status":"ok","timestamp":1702587968393,"user_tz":-420,"elapsed":3,"user":{"displayName":"Minh Nguy·ªÖn ƒê·∫∑ng Nh·∫≠t","userId":"06013224096912534741"}}},"outputs":[],"source":["def text_recognition(img, data_transforms, text_reg_model, idx_to_char, device):\n","    transformed_image = data_transforms(img)\n","    transformed_image = transformed_image.unsqueeze(0).to(device)\n","    text_reg_model.eval()\n","    with torch.no_grad():\n","        logits = text_reg_model(transformed_image).detach().cpu()\n","    text = decode(logits.permute(1, 0, 2).argmax(2), idx_to_char)\n","\n","    return text"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"TwFcGdDuH3LS","executionInfo":{"status":"ok","timestamp":1702587971821,"user_tz":-420,"elapsed":576,"user":{"displayName":"Minh Nguy·ªÖn ƒê·∫∑ng Nh·∫≠t","userId":"06013224096912534741"}}},"outputs":[],"source":["def visualize_detections(img, detections):\n","    plt.figure(figsize=(12, 8))\n","    plt.imshow(img)\n","    plt.axis('off')\n","\n","    for bbox, detected_class, confidence, transcribed_text in detections:\n","        x1, y1, x2, y2 = bbox\n","        plt.gca().add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor='red', linewidth=2))\n","        plt.text(\n","            x1, y1 - 10, f\"{detected_class} ({confidence:.2f}): {transcribed_text}\",\n","            fontsize=9, bbox=dict(facecolor='red', alpha=0.5)\n","        )\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":417,"status":"ok","timestamp":1702588397934,"user":{"displayName":"Minh Nguy·ªÖn ƒê·∫∑ng Nh·∫≠t","userId":"06013224096912534741"},"user_tz":-420},"id":"-5f9TwiTQSQd"},"outputs":[],"source":["data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.Resize((100, 420)),\n","        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n","        transforms.Grayscale(num_output_channels=1),\n","        transforms.GaussianBlur(3),\n","        transforms.RandomAffine(degrees=1, shear=1),\n","        transforms.RandomPerspective(distortion_scale=0.2, p=0.3, interpolation=3),\n","        transforms.RandomRotation(degrees=2),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5,), (0.5,)),\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize((100, 420)),\n","        transforms.Grayscale(num_output_channels=1),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5,), (0.5,)),\n","    ]),\n","}\n","\n","def predict(img_path, data_transforms, text_det_model, text_reg_model, idx_to_char, device):\n","    # Detection\n","    bboxes, classes, names, confs = text_detection(img_path, text_det_model)\n","\n","    # Load the image\n","    img = Image.open(img_path)\n","\n","    predictions = []\n","\n","    # Iterate through the results\n","    for bbox, cls, conf in zip(bboxes, classes, confs):\n","        x1, y1, x2, y2 = bbox\n","        confidence = conf\n","        detected_class = cls\n","        name = names[int(cls)]\n","\n","        # Extract the detected object and crop it\n","        cropped_image = img.crop((x1, y1, x2, y2))\n","\n","        transcribed_text = text_recognition(\n","            cropped_image,\n","            data_transforms,\n","            text_reg_model,\n","            idx_to_char,\n","            device\n","        )\n","\n","        predictions.append((bbox, name, confidence, transcribed_text))\n","\n","    visualize_detections(img, predictions)\n","\n","    return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1NHiDWzdIWRuQdk6x-_POXMku5APY1BWV"},"id":"p7T9ZfZXQSQd","outputId":"d6db335a-ed26-4741-fe55-98f128c921a4","scrolled":false},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["img_dir = '/content/drive/MyDrive/SceneTextRecognition/icdar2003/SceneTrialTrain/lfsosa_12.08.2002'\n","inf_transforms = data_transforms['val']\n","\n","for img_filename in os.listdir(img_dir):\n","    img_path = os.path.join(img_dir, img_filename)\n","    predictions = predict(\n","        img_path,\n","        data_transforms=inf_transforms,\n","        text_det_model=yolo,\n","        text_reg_model=crnn_model,\n","        idx_to_char=idx_to_char,\n","        device=device\n","    )"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}